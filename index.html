<!doctype html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <title>Haozhe Ma</title>
    <link rel="stylesheet" href="assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="assets/css/fontawsom-all.min.css">
    <link rel="stylesheet" type="text/css" href="assets/css/style.css"/>
    <link rel="stylesheet" type="text/css" href="assets/css/zui.css"/>
    <style>
        .label {
            display: inline
        }

        .paper-item {
            display: flex;
            margin-top: 10px;
            flex-direction: row;
            align-items: flex-start;
        }

        @media (max-width: 768px) {
            .paper-item {
                flex-direction: column;
            }
        }

        .paper-item .paper-label {
            width: 150px;
            padding: 0;
            margin: 0;
            text-indent: 0
        }

        .paper-item .project-label {
            width: 30px;
            padding: 0;
            margin: 0;
            text-indent: 0
        }

        .paper-item .project-link {
            width: 180px;
            text-align: right;
            margin-top: 0;
            margin-left: auto;
            margin-right: 10px;
        }

        @media (max-width: 768px) {
            .paper-item .project-link {
                width: 100%;
                text-align: left;
                margin-left: 0;
                margin-top: 10px;
            }
        }


    </style>
</head>

<body>
<div class="container">
    <div class="container profile-container">
        <div class="row">
            <div id="menu-jk" class="col-md-3">
                <div class="pro-s-cover">
                    <div style="width: 80%;margin: 0 auto">
                        <img style="border-radius: var(--radius-full)" src="assets/images/avatar-2.png" alt="">
                    </div>
                    <h6>Haozhe Ma</h6>
                    <p>Ph.D. Student</p>
                    <p>National University of Singapore (NUS)</p>
                </div>
                <div class="con-cover">
                    <h4>Contact</h4>
                    <div class="cd-ro row no-margin">
                        <p><i class="icon icon-map-marker"></i> Singapore</p>
                        <p><i class="icon icon-envelope"></i><a
                                href="mailto:haozhe.ma@u.nus.edu">haozhe.ma[at]u.nus.edu</a></p>
                        <p><i class="fab fa-google"></i><a
                                href="https://scholar.google.com/citations?user=9eitZlYAAAAJ" target="_blank">Google Scholar</a></p>
                        <p><i class="fab fa-github"></i><a href="https://github.com/mahaozhe" target="_blank">GitHub</a></p>
                        <p><i class="fab fa-linkedin"></i><a href="https://www.linkedin.com/in/haozhe-ma-592b42310/" target="_blank">Linked
                            In</a></p>
                        <p><i class="icon icon-wechat"></i>WeChat: Fu_Yibai</p>
                    </div>
                </div>
            </div>
            <div class="col-md-9">
                <div class="data-box" style="font-size: 18px">
                    <p>I'm a Ph.D. candidate in School of Computing at National University of Singapore.
                        My advisor is Professor <a href="https://www.comp.nus.edu.sg/~leongty/">Leong Tze Yun</a>.</p>
                    <p>My research interests include
                        <span class="label primary-ghost size-lg">Reinforcement Learning</span>,
                        <span class="label primary-ghost size-lg">Reward Shaping</span>,
                        <!-- <span class="label primary-ghost size-lg">AI Agent Decision-Making</span>, -->
                        <!-- <span class="label primary-ghost size-lg">Large Language Models</span>, -->
                        <!-- and <span class="label primary-ghost size-lg">Robotics</span>.</p> -->
                        and <span class="label primary-ghost size-lg">Search Systems</span>.</p>
                    
                    <!-- 
                    <br>
                    <p><span class="label important size-sm">NEW!</span>&nbsp;&nbsp;&nbsp;&nbsp;I'm looking for researcher job/intern opportunities. I'd very much welcome your consideration. My CV is available to <a href="./files/CV-MaHaozhe-PhD-Computer-Science-NUS.pdf" target="_blank">download here</a>.</p> 
                    -->
                   
                </div>
                <div class="data-box">
                    <h2>Publications</h2>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">NeurIPS 2025</span></p>
                        <p style="text-indent: 0;">Centralized Reward Agent for Knowledge Sharing and Transfer in Multi-Task Reinforcement Learning<br>
                            <b>Haozhe Ma</b>, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong. <br>
                            39th Annual Conference on Neural Information Processing Systems (NeurIPS), 2025 <br>
                            <a href="https://arxiv.org/abs/2408.10858" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://arxiv.org/pdf/2408.10858" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://github.com/mahaozhe/CenRA" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Codes</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">ICML 2025</span></p>
                        <p style="text-indent: 0;">Catching Two Birds with One Stone: Reward Shaping with Dual Random Networks for Balancing Exploration and Exploitation<br>
                            <b>Haozhe Ma</b>, Fangling Li, Jing Yu Lim, Zhengding Luo, Thanh Vinh Vo, Tze-Yun Leong. <br>
                            42nd International Conference on Machine Learning (ICML), 2025 <br>
                            <a href="https://icml.cc/virtual/2025/poster/44893" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://openreview.net/pdf?id=YqtgKdW9dD" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://github.com/mahaozhe/DuRND" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Codes</button>
                            </a>
                            <a href="https://recorder-v3.slideslive.com/?share=101177&s=d1f930b0-0112-4dbd-923f-d4a44f3d6d9f" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Presentation</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">ICLR 2025</span></p>
                        <p style="text-indent: 0;">Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning<br>
                            <b>Haozhe Ma</b>, Zhengding Luo, Thanh Vinh Vo, Kuankuan Sima, Tze-Yun Leong. <br>
                            13th International Conference on Learning Representations (ICLR), 2025 <br>
                            <a href="https://arxiv.org/abs/2408.03029" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://arxiv.org/pdf/2408.03029" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://github.com/mahaozhe/SASR" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Codes</button>
                            </a>
                            <a href="https://iclr.cc/media/PosterPDFs/ICLR%202025/29692.png?t=1744035765.217248" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Poster</button>
                            </a>
                            <a href="https://recorder-v3.slideslive.com/?share=100443&s=4ccc0bc8-324f-4b88-af8e-50957905c023" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Presentation</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">ICML 2024</span></p>
                        <p style="text-indent: 0;">Reward Shaping for Reinforcement Learning with An Assistant Reward Agent. <br>
                            <b>Haozhe Ma</b>, Kuankuan Sima, Thanh Vinh Vo, Di Fu, Tze-Yun Leong. <br>
                            41st International Conference on Machine Learning (ICML), 2024 <br>
                            <a href="https://proceedings.mlr.press/v235/ma24l.html" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://openreview.net/pdf?id=a3XFF0PGLU" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://github.com/mahaozhe/ReLara" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Codes</button>
                            </a>
                            <a href="https://www.researchgate.net/publication/382303900_Reward_Shaping_for_Reinforcement_Learning_with_An_Assistant_Reward_Agent" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Poster</button>
                            </a>
                            <a href="https://www.youtube.com/watch?v=k9OSrdcC8Qo" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Presentation</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">Preprint</span></p>
                        <p style="text-indent: 0;">Exploration by Random Reward Perturbation<br>
                            <b>Haozhe Ma</b>, Guoji Fu, Zhengding Luo, Jiele Wu, Tze-Yun Leong. <br>
                            <a href="https://www.arxiv.org/abs/2506.08737" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://www.arxiv.org/pdf/2506.08737" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">AAMAS 2024</span> <br> <span class="label special size-sm">Oral</span> </p>
                        <p style="text-indent: 0;">Mixed-Initiative Bayesian Sub-Goal Optimization in Hierarchical Reinforcement Learning. <br>
                            <b>Haozhe Ma</b>, Thanh Vinh Vo, Tze-Yun Leong. <br>
                            23rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2024 <br>
                            <a href="https://dl.acm.org/doi/10.5555/3635637.3662991" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://www.ifaamas.org/Proceedings/aamas2024/pdfs/p1328.pdf" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Poster</button>
                            </a>
                            <a href="" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Oral Slides</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">NN 2024</span></p>
                        <p style="text-indent: 0;">GFANC-RL: Reinforcement Learning-based Generative Fixed-filter Active Noise Control. <br>
                            Zhengding Luo*, <b>Haozhe Ma</b>*, Dongyuan Shi, Woon-Seng Gan. <br>
                            *Equal contribution. <br>
                            Neural Networks Journal, 2024. (Impact Factor: 6.0) <br>
                            <a href="https://www.sciencedirect.com/science/article/abs/pii/S0893608024006117" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://github.com/Luo-Zhengding/GFANC-RL" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Codes</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">AAMAS 2023</span></p>
                        <p style="text-indent: 0;">Hierarchical Reinforcement Learning with Human-AI Collaborative Sub-Goals Optimization. <br>
                            <b>Haozhe Ma</b>, Thanh Vinh Vo, Tze-Yun Leong. <br>
                            22rd International Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2023 <br>
                            <a href="https://dl.acm.org/doi/abs/10.5555/3545946.3598917" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://openreview.net/pdf?id=59_waYW8fC" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://www.researchgate.net/publication/373512280_Hierarchical_Reinforcement_Learning_with_Human-AI_Collaborative_Sub-Goal_Optimization" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Poster</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">AAAI Sym. 2023</span></p>
                        <p style="text-indent: 0;">Human-AI Collaborative Sub-Goal Optimization in Hierarchical Reinforcement Learning.<br>
                            <b>Haozhe Ma</b>, Thanh Vinh Vo, Tze-Yun Leong. <br>
                            Inaugural Summer Symposium Series 2023 of AAAI, 2023 <br>
                            <a href="https://ojs.aaai.org/index.php/AAAI-SS/article/view/27481" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://ojs.aaai.org/index.php/AAAI-SS/article/view/27481/27254" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://www.researchgate.net/publication/380174381_Human-AI_Collaborative_Sub-Goal_Optimization_in_Hierarchical_Reinforcement_Learning_Motivation" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Oral Slides</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">MSSP 2025</span></p>
                        <p style="text-indent: 0;">Deep learning-based Generative Fixed-Filter Active Noise Control: Transferability and implementation. <br>
                            Zhengding Luo, Junwei Ji, Boxiang Wang, Dongyuan Shi, <b>Haozhe Ma</b>, Woon-Seng Gan. <br>
                            Mechanical Systems and Signal Processing Journal, 2025. (Impact Factor: 8.9) <br>
                            <a href="https://www.sciencedirect.com/science/article/pii/S0888327025009082" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                        </p>
                    </div>
                    
                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">CoLLAs 2024</span></p>
                        <p style="text-indent: 0;">Decoupled Prompt-Adapter Tuning for Continual Activity Recognition <br>
                            Di Fu, Thanh Vinh Vo, <b>Haozhe Ma</b>, Tze-Yun Leong. <br>
                            Conference on Lifelong Learning Agents (CoLLAs), 2024 <br>
                            <a href="https://arxiv.org/abs/2407.14811" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://arxiv.org/pdf/2407.14811" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                            <a href="https://www.youtube.com/watch?v=FjVs1CUi_6A&t=543s" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Presentation</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">Preprint</span></p>
                        <p style="text-indent: 0;">Causal Policy Learning in Reinforcement Learning: Backdoor-Adjusted Soft Actor-Critic<br>
                            Thanh Vinh Vo, Young Lee, <b>Haozhe Ma</b>, Chien Lu, Tze-Yun Leong. <br>
                            <a href="https://arxiv.org/abs/2506.05445" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://arxiv.org/pdf/2506.05445" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                        </p>
                    </div>
                    
                    <div class="paper-item">
                        <p class="paper-label" style="text-indent: 0"><span class="label primary size-sm">Preprint</span></p>
                        <p style="text-indent: 0;">JEDI: Latent End-to-end Diffusion Mitigates Agent-Human Performance Asymmetry in Model-Based Reinforcement Learning<br>
                            Jing Yu Lim, Zarif Ikram, Samson Yu, <b>Haozhe Ma</b>, Tze-Yun Leong, Dianbo Liu. <br>
                            <a href="https://arxiv.org/abs/2505.19698" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">Paper</button>
                            </a>
                            <a href="https://arxiv.org/pdf/2505.19698" target="_blank">
                                <button type="button" class="btn size-sm primary-pale">PDF</button>
                            </a>
                        </p>
                    </div>

                </div>

                <div class="data-box education-detail">
                    <h2>Education</h2>
                    <div class="service no-margin row">
                        <div class="col-sm-3 no-padding resume-dat serv-logo">
                            <h6>Jan 2022 - Now</h6>
                            <p>Ph.D. Degree</p>
                        </div>
                        <div class="col-sm-9 rgbf">
                            <h5>National University of Singapore (NUS)</h5>
                            <p style="text-indent: 0">School of Computing</p>
                            <!-- <p style="text-indent: 0">Computer Science, School of Computing</p> -->
                        </div>
                    </div>
                    <div class="service no-margin row">
                        <div class="col-sm-3 no-padding resume-dat serv-logo">
                            <h6>Aug 2020 - Dec 2021</h6>
                            <p>Master Degree</p>
                        </div>
                        <div class="col-sm-9 rgbf">
                            <h5>National University of Singapore (NUS)</h5>
                            <!-- <p style="text-indent: 0">Computer Science, School of Computing</p> -->
                            <p style="text-indent: 0">School of Computing</p>
                        </div>
                    </div>
                    <div class="service no-margin row">
                        <div class="col-sm-3 no-padding resume-dat serv-logo">
                            <h6>Aug 2016 - Jun 2020</h6>
                            <p>Bachelor Degree</p>
                        </div>
                        <div class="col-sm-9 rgbf">
                            <h5>Xi'an Jiaotong University (XJTU)</h5>
                            <p style="text-indent: 0">Computer Science and Engineering</p>
                            <!-- <p style="text-indent: 0">Computer Science, Qian Xuesen Top Class</p> -->
                        </div>
                    </div>
                </div>

                <div class="data-box">
                    <h2>Awards</h2>
                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">PhD Research Achievement Award of National University of Singapore (AY2024-2025).&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://credentials.nus.edu.sg/604ac40f-c6af-4399-96d2-4e653af52be1" target="_blank"><button type="button" class="btn size-sm primary-pale">Certificate</button></a></p>
                    </div>
                    
                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">PhD Research Achievement Award of National University of Singapore (AY2023-2024).&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://credentials.nus.edu.sg/bbbfd521-a961-4e06-b26b-5deba92d0872" target="_blank"><button type="button" class="btn size-sm primary-pale">Certificate</button></a></p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Research Incentive Award of School of Computing of National University of Singapore (AY2022-2023)</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Research Scholarship from the Ministry of Education in Singapore (2022-2026).</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Scholarship of International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2024).</p>
                    </div>
<!-- 
                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Outstanding Student Scholarship of Xiâ€™an Jiaotong University.</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">SiYuan Student Scholarship of Xi'an Jiaotong University.</p>
                    </div> -->

                </div>

                <div class="data-box">
                    <h2>Academic Duty</h2>
                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;"><b>Student Area Search Committee</b> for faculty recruitment for School of Computing, National University of Singapore.</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;"><b>Reviewers</b> of conferences and journals: ICLR, ICML, NeurIPS, AAMAS, TSP etc.</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;"><b>Teaching Assistant</b> of the undergraduate course Foundations of Artificial Intelligence.</p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;"><b>Teaching Assistant</b> of the graduate course AI Planning and Decision Making.</p>
                    </div>


                </div>

                <div class="data-box">
                    <h2>Open-Sourse Projects</h2>
                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">[ICML 2025] Dual Random Network Distillation (DuRND)</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/DuRND" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">[ICLR 2025] Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/SASR" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">[ICML 2024] Reward Shaping for Reinforcement Learning with an Assistant Reward Agent</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/ReLara" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Efficient Reinforcement Learning Algorithms and Environments by PyTorch</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/RLAlgorithms" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Flat Reinforcement Learning Algorithms on StartCraft II Mini-Games</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/SCII_RL" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Tutorial and Document: Using StarCraft II as Learning Environment</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/HowToUsePySC2" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                    <div class="paper-item">
                        <p class="project-label" style="text-indent: 0"><i class="icon icon-play"></i></p>
                        <p style="text-indent: 0;">Auto Text Recognition and Translation by Pasting Screenshots</p>
                        <p class="project-link" style="text-indent: 0;">
                            <a href="https://github.com/mahaozhe/PasteOCR" target="_blank">
                                <button type="button" class="btn size-sm primary-pale"><i class="icon icon-github"></i>Project Link</button>
                            </a>
                        </p>
                    </div>

                </div>

            </div>
        </div>
    </div>
</div>
</body>

</html>